{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnE96wJO+f3cFX/ags7Azq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlekanmaVictoria/Data-science-Portfolio/blob/main/Task_Dental_Image_Analysis_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: Dental Image Processing Pipeline**\n",
        "## **Overview**\n",
        "This pipeline processes a set of images using techniques including image alignment, focus stacking, segmentation, and region measurement. The goal is to create a focus-composited image, segment the image, and measure and annotate different regions within it.\n",
        "\n",
        "# **1. Downloading Images**\n",
        "## **Objective:**\n",
        " Download a folder of images from Google Drive for processing."
      ],
      "metadata": {
        "id": "JU_SksN7UKbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# URL to the Google Drive folder containing images\n",
        "url = 'https://drive.google.com/drive/folders/1KuUPqc-Gd1YwULdlSkIw9GCFYsHx4izp?usp=sharing'\n",
        "\n",
        "# Download the folder containing images\n",
        "gdown.download_folder(url, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuA4HdfkUWSk",
        "outputId": "b9f3b8bd-e7a7-49a4-9ce8-e689693aa352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1ZWy_k7frsw_YWZlmohP2d_qWbFD-3wJZ 1球あり.png\n",
            "Processing file 1z4P6M293XPXP6iG6vQPfhbXUyLPECYQi 2.png\n",
            "Processing file 1BGJGd9-vMgdi0mkgS-IfuAWQO9IEyZYJ 3.png\n",
            "Processing file 1kNYdha4lu82_Nu36vT8Hrl7EXdebWgFQ 4.png\n",
            "Processing file 1eSM5TMuJ3EJSpApZDIvMoldTS0jSNEXn 5.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZWy_k7frsw_YWZlmohP2d_qWbFD-3wJZ\n",
            "To: /content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/1球あり.png\n",
            "100%|██████████| 1.91M/1.91M [00:00<00:00, 35.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z4P6M293XPXP6iG6vQPfhbXUyLPECYQi\n",
            "To: /content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/2.png\n",
            "100%|██████████| 1.87M/1.87M [00:00<00:00, 24.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BGJGd9-vMgdi0mkgS-IfuAWQO9IEyZYJ\n",
            "To: /content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/3.png\n",
            "100%|██████████| 1.84M/1.84M [00:00<00:00, 28.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kNYdha4lu82_Nu36vT8Hrl7EXdebWgFQ\n",
            "To: /content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/4.png\n",
            "100%|██████████| 1.85M/1.85M [00:00<00:00, 40.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eSM5TMuJ3EJSpApZDIvMoldTS0jSNEXn\n",
            "To: /content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/5.png\n",
            "100%|██████████| 1.98M/1.98M [00:00<00:00, 57.1MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/1球あり.png',\n",
              " '/content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/2.png',\n",
              " '/content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/3.png',\n",
              " '/content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/4.png',\n",
              " '/content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様/5.png']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Description:**\n",
        "The images are downloaded from a shared Google Drive folder using gdown.\n",
        "Ensure that the URL is correct and accessible."
      ],
      "metadata": {
        "id": "97a56ZuGUa4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Loading and Aligning Images**\n",
        "## **Objective:**\n",
        "Load images and align them to a reference image using feature matching."
      ],
      "metadata": {
        "id": "EQPWw1-aUpMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Path to the folder containing images\n",
        "folder_path = '/content/大阪歯科大学附属病院有歯補綴咬合学講座堀 圭佑様'\n",
        "\n",
        "# List all image files\n",
        "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Load images in color\n",
        "base_image = cv2.imread(image_files[0])\n",
        "images = [cv2.imread(img_path) for img_path in image_files]\n",
        "\n",
        "# Function to align images\n",
        "def align_images(base_image, images):\n",
        "    aligned_images = []\n",
        "    orb = cv2.ORB_create()\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY), None)\n",
        "\n",
        "    for img in images:\n",
        "        keypoints2, descriptors2 = orb.detectAndCompute(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), None)\n",
        "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "        matches = matcher.match(descriptors1, descriptors2)\n",
        "        matches = sorted(matches, key=lambda x: x.distance)\n",
        "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "        matrix, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
        "        height, width, channels = base_image.shape\n",
        "        aligned_image = cv2.warpPerspective(img, matrix, (width, height))\n",
        "        aligned_images.append(aligned_image)\n",
        "    return aligned_images\n",
        "\n",
        "# Align the images\n",
        "aligned_images = align_images(base_image, images)\n"
      ],
      "metadata": {
        "id": "Pv7FZn0CUmNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Description:**\n",
        "Images are aligned to the base image using ORB feature matching and homography transformation. This ensures that all images are registered in the same coordinate system.\n",
        "\n",
        "# **3. Focus Stacking**\n",
        "Objective: Create a focus-composited image by combining the aligned images."
      ],
      "metadata": {
        "id": "NjQ9At34UyU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to focus stack images\n",
        "def focus_stack(aligned_images):\n",
        "    stack = np.max(np.array(aligned_images), axis=0)\n",
        "    return stack\n",
        "\n",
        "# Create focus-composited image\n",
        "focused_stack = focus_stack(aligned_images)\n",
        "cv2.imwrite('Focus_Composited_Image.jpg', focused_stack)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1HwJIF5U6TI",
        "outputId": "df5120ad-d50b-4b5c-8c3e-64196aac3005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Description:**\n",
        "The focus-composited image is generated by taking the maximum pixel values from the aligned images, effectively combining focused regions from multiple images.\n",
        "\n",
        "# **4. Image Segmentation**\n",
        "Objective: Segment the focus-composited image to identify different regions."
      ],
      "metadata": {
        "id": "qYZNcE93VOe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import measure, filters, morphology, color\n",
        "\n",
        "# Function to segment the image\n",
        "def segment_image(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    thresh = filters.threshold_otsu(gray_image)\n",
        "    binary_mask = gray_image > thresh\n",
        "    cleaned_mask = morphology.remove_small_objects(binary_mask, min_size=500)\n",
        "    cleaned_mask = morphology.closing(cleaned_mask, morphology.square(3))\n",
        "    labeled_image = measure.label(cleaned_mask)\n",
        "    return labeled_image\n",
        "\n",
        "# Segment the focus-composited image\n",
        "segmented_image = segment_image(focused_stack)\n",
        "segmented_image_colored = color.label2rgb(segmented_image, bg_label=0, image=focused_stack)\n",
        "cv2.imwrite('Segmented_Image.jpg', cv2.cvtColor((segmented_image_colored * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIxT2hkFVXkf",
        "outputId": "3332f058-3820-4433-8079-75f9b1139abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Description:**\n",
        "The image is segmented using Otsu’s thresholding and morphological operations. This process generates a labeled image where each region corresponds to a different segment.\n",
        "\n",
        "# **5. Merging Segmented Images**\n",
        "Objective: Merge segmented regions into a single image."
      ],
      "metadata": {
        "id": "1pPgszHBVf_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to merge segmented images\n",
        "def merge_segmented_images(image, segments):\n",
        "    merged_image = np.zeros_like(image)\n",
        "    for segment in np.unique(segments):\n",
        "        if segment == 0:\n",
        "            continue\n",
        "        mask = segments == segment\n",
        "        merged_image[mask] = image[mask]\n",
        "    return merged_image\n",
        "\n",
        "# Create merged segmented image\n",
        "merged_image = merge_segmented_images(focused_stack, segmented_image)\n",
        "cv2.imwrite('Merged_Segmented_Image.jpg', merged_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROX75FUDVjl5",
        "outputId": "09c09cbd-1d50-4b2c-c78d-f76c09f96c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Description:**\n",
        "Segmented regions are merged into a single image where each region is highlighted. This step helps in visualizing and analyzing specific areas of interest."
      ],
      "metadata": {
        "id": "xbfMv_T0VrHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Annotating and Measuring Regions**\n",
        "Objective: Measure regions and annotate the segmented image with their labels and areas."
      ],
      "metadata": {
        "id": "9N2eNVv7Vy8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to measure regions and annotate the image\n",
        "def measure_regions(image, segments):\n",
        "    regions = measure.regionprops(segments)\n",
        "    areas = []\n",
        "    annotated_image = image.copy()\n",
        "    for idx, region in enumerate(regions):\n",
        "        if region.label != 0:\n",
        "            areas.append((region.label, region.area))\n",
        "            # Draw the label number on the image\n",
        "            minr, minc, maxr, maxc = region.bbox\n",
        "            cv2.putText(annotated_image, str(idx + 1), (minc, minr), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "    return areas, annotated_image\n",
        "\n",
        "# Annotate segmented image with labels\n",
        "areas, annotated_image = measure_regions(focused_stack, segmented_image)\n",
        "cv2.imwrite('Annotated_Segmented_Image.jpg', annotated_image)\n",
        "\n",
        "# Save areas to Excel with labels\n",
        "areas_df = pd.DataFrame(areas, columns=['Segment Number', 'Area'])\n",
        "areas_df.to_excel('Segment_Areas_Report.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "_gfm1FUYV1W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHB0IklScHRV",
        "outputId": "b975956c-03b7-4d8e-97c4-880b73da1f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Description:**\n",
        "Each segmented region is measured for its area and annotated with its label on the image. The results are saved in an Excel file for further analysis.\n",
        "\n",
        "# **Summary of Changes**\n",
        "**Downloading Images**:The images are downloaded from a Google Drive folder.\n",
        "\n",
        "**Aligning Images**:\n",
        "Images are aligned using ORB feature matching and homography transformation.\n",
        "\n",
        "**Focus Stacking**:\n",
        "A focus-composited image is created by taking the maximum pixel values from the aligned images.\n",
        "\n",
        "**Segmenting Image**:\n",
        " The focus-composited image is segmented using Otsu’s thresholding and morphological operations.\n",
        "\n",
        "**Merging Segmented Images**: The segmented image is merged to highlight target areas.\n",
        "\n",
        "**Annotating Segmented Image**: Each segmented area is labeled with a number corresponding to its measurement.\n",
        "**Saving to Excel:** The areas of the segmented regions are saved to an Excel file."
      ],
      "metadata": {
        "id": "AAx4hMmXV8pE"
      }
    }
  ]
}