{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlekanmaVictoria/Artificial-intelligence-Data-science-Portfolio/blob/main/AI_Method_for_Distinguishing_Benign_and_Malignant_Colony_Cells.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6cp3LCzQ60X"
      },
      "source": [
        "# **AI Method for Distinguishing Benign and Malignant Colony Cells**\n",
        "\n",
        "## 1. **Introduction**\n",
        "This notebook provides an implementation of an AI method for distinguishing between benign and malignant colony cells using a convolutional neural network (CNN). The process includes data extraction from PowerPoint files, preprocessing, model training, and evaluation.\n",
        "\n",
        "## 2. **Setup and Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGL8oBVU3oo9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0dPc0rbMMSO",
        "outputId": "fa9b6ddd-89b7-44ee-ddcc-52310242aad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.0 python-pptx-0.6.23\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install tensorflow opencv-python scikit-learn pandas numpy matplotlib seaborn gdown python-pptx\n",
        "\n",
        "# Importing required libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "import gdown\n",
        "from pptx import Presentation\n",
        "from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
        "from io import BytesIO\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp4MHbl1RJyl"
      },
      "source": [
        "## **Explanation:**\n",
        "\n",
        "Libraries: We install and import libraries required for handling PowerPoint files, image processing, and building the CNN.\n",
        "\n",
        "# 3. **Data Extraction from PowerPoint Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgIeoi1cMQ7J"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive to access dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku-iqJw0MbWh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGw201vyMe_g",
        "outputId": "015bb928-f827-435d-f877-e7af214ff7be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 1nz7gHH8UZs5q-A2i25w1IXmzYN58T10I EPC Colony Quiz 2 - unlabeled70.pptx\n",
            "Processing file 1L1_Uu6pCLSHH4_aOYvgRkzLUYjNYNYOi EPC Colony Quiz_unlabeled.pptx\n",
            "Processing file 12S33g21hRqqhYpQGiiUBe8N8PLHjiFU8 EPC-CFU Labeled-images.pptx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nz7gHH8UZs5q-A2i25w1IXmzYN58T10I\n",
            "To: /content/dataset/EPC Colony Quiz 2 - unlabeled70.pptx\n",
            "100%|██████████| 73.5M/73.5M [00:02<00:00, 30.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L1_Uu6pCLSHH4_aOYvgRkzLUYjNYNYOi\n",
            "To: /content/dataset/EPC Colony Quiz_unlabeled.pptx\n",
            "100%|██████████| 11.7M/11.7M [00:00<00:00, 21.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12S33g21hRqqhYpQGiiUBe8N8PLHjiFU8\n",
            "To: /content/dataset/EPC-CFU Labeled-images.pptx\n",
            "100%|██████████| 15.4M/15.4M [00:00<00:00, 121MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "# Define Google Drive folder ID and download files\n",
        "file_id = \"1LMRPoqs9E8FWBK-eoBDrdVlC4tuIUmH6\"\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/{file_id}\", output=\"./dataset\", quiet=False, use_cookies=False)\n",
        "\n",
        "# Path to the downloaded dataset\n",
        "dataset_path = \"./dataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzm8c86DMggb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODL5YfqKM927"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlJFO4DTM96O"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SyVVQPnMgjp"
      },
      "outputs": [],
      "source": [
        "def extract_images_from_pptx(pptx_path, output_dir):\n",
        "    \"\"\"Extract images from a PowerPoint file and save them to the specified directory.\"\"\"\n",
        "    prs = Presentation(pptx_path)\n",
        "    image_counter = 0\n",
        "    for idx, slide in enumerate(prs.slides):\n",
        "        for shape in slide.shapes:\n",
        "            if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n",
        "                image = shape.image\n",
        "                image_bytes = image.blob\n",
        "                image_stream = BytesIO(image_bytes)\n",
        "                img = Image.open(image_stream)\n",
        "                img.save(os.path.join(output_dir, f\"slide{idx}_image{image_counter}.png\"))\n",
        "                image_counter += 1\n",
        "\n",
        "# Create directories for the extracted images\n",
        "os.makedirs(os.path.join(dataset_path, \"EPC_Colony_Quiz_2\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dataset_path, \"EPC_Colony_Quiz\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dataset_path, \"EPC_CFU_Labeled\"), exist_ok=True)\n",
        "\n",
        "# Extract images from each PowerPoint file\n",
        "extract_images_from_pptx(os.path.join(dataset_path, \"EPC Colony Quiz 2 - unlabeled70.pptx\"), os.path.join(dataset_path, \"EPC_Colony_Quiz_2\"))\n",
        "extract_images_from_pptx(os.path.join(dataset_path, \"EPC Colony Quiz_unlabeled.pptx\"), os.path.join(dataset_path, \"EPC_Colony_Quiz\"))\n",
        "extract_images_from_pptx(os.path.join(dataset_path, \"EPC-CFU Labeled-images.pptx\"), os.path.join(dataset_path, \"EPC_CFU_Labeled\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eXCJuK4MliQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeWiSOKCNgPN"
      },
      "source": [
        "**Explanation:**\n",
        "\n",
        "Function extract_images_from_pptx: Extracts images from PowerPoint files and saves them to a specified directory.\n",
        "Usage: Paths to the PowerPoint files are provided, and images are saved to corresponding directories.\n",
        "## 4**.Data Loading and Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aewwTbhNgSe"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYCwPXiKMlll"
      },
      "outputs": [],
      "source": [
        "def load_data_from_directory(directory_path, label, target_size=(128, 128)):\n",
        "    \"\"\"Load images from a directory, resize them, and assign a label.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_name in os.listdir(directory_path):\n",
        "        image_path = os.path.join(directory_path, image_name)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if image is not None:\n",
        "            resized_image = cv2.resize(image, target_size)\n",
        "            images.append(resized_image)\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Load images and labels from all directories with resizing\n",
        "images_1, labels_1 = load_data_from_directory(os.path.join(dataset_path, \"EPC_Colony_Quiz_2\"), \"benign\")\n",
        "images_2, labels_2 = load_data_from_directory(os.path.join(dataset_path, \"EPC_Colony_Quiz\"), \"benign\")\n",
        "images_3, labels_3 = load_data_from_directory(os.path.join(dataset_path, \"EPC_CFU_Labeled\"), \"malignant\")\n",
        "\n",
        "# Combine all images and labels\n",
        "images = np.array(images_1 + images_2 + images_3)\n",
        "labels = np.array(labels_1 + labels_2 + labels_3)\n",
        "\n",
        "# Data preprocessing\n",
        "images = images / 255.0  # Normalize pixel values to [0, 1]\n",
        "images = np.expand_dims(images, axis=-1)  # Add channel dimension\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ZP4VBBNnZS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV4daGPINncp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z5qieOMNnrj"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Fit the data generator\n",
        "datagen.fit(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPG4uRuIN6d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44KEUm0ZN6hN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcKpg4xbOYZc",
        "outputId": "e6a899a6-4278-489f-bd36-10a387e9cd2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3304322 (12.60 MB)\n",
            "Trainable params: 3304322 (12.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 910ms/step - loss: 0.8549 - accuracy: 0.5900 - val_loss: 0.4564 - val_accuracy: 0.8846\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.5855 - accuracy: 0.7700 - val_loss: 0.4539 - val_accuracy: 0.8846\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5835 - accuracy: 0.7700 - val_loss: 0.4822 - val_accuracy: 0.8846\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 3s 757ms/step - loss: 0.5924 - accuracy: 0.7700 - val_loss: 0.4753 - val_accuracy: 0.8846\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 0.5975 - accuracy: 0.7700 - val_loss: 0.3850 - val_accuracy: 0.8846\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 3s 986ms/step - loss: 0.6358 - accuracy: 0.7700 - val_loss: 0.4235 - val_accuracy: 0.8846\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5400 - accuracy: 0.7700 - val_loss: 0.4453 - val_accuracy: 0.8846\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 3s 983ms/step - loss: 0.5403 - accuracy: 0.7700 - val_loss: 0.4603 - val_accuracy: 0.8846\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 4s 969ms/step - loss: 0.5673 - accuracy: 0.7700 - val_loss: 0.4437 - val_accuracy: 0.8846\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5703 - accuracy: 0.7700 - val_loss: 0.4431 - val_accuracy: 0.8846\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.5549 - accuracy: 0.7700 - val_loss: 0.4406 - val_accuracy: 0.8846\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.5463 - accuracy: 0.7700 - val_loss: 0.4036 - val_accuracy: 0.8846\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.5948 - accuracy: 0.7700 - val_loss: 0.3764 - val_accuracy: 0.8846\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 4s 787ms/step - loss: 0.5719 - accuracy: 0.7700 - val_loss: 0.3978 - val_accuracy: 0.8846\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 3s 997ms/step - loss: 0.5633 - accuracy: 0.7700 - val_loss: 0.4181 - val_accuracy: 0.8846\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 3s 718ms/step - loss: 0.5633 - accuracy: 0.7700 - val_loss: 0.3970 - val_accuracy: 0.8846\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5506 - accuracy: 0.7700 - val_loss: 0.3936 - val_accuracy: 0.8846\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.5448 - accuracy: 0.7700 - val_loss: 0.3743 - val_accuracy: 0.8846\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 3s 706ms/step - loss: 0.5497 - accuracy: 0.7700 - val_loss: 0.3786 - val_accuracy: 0.8846\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5648 - accuracy: 0.7700 - val_loss: 0.3614 - val_accuracy: 0.8846\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5923 - accuracy: 0.7700 - val_loss: 0.5178 - val_accuracy: 0.8846\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 3s 732ms/step - loss: 0.5554 - accuracy: 0.7700 - val_loss: 0.5021 - val_accuracy: 0.8846\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 3s 977ms/step - loss: 0.5211 - accuracy: 0.7700 - val_loss: 0.3607 - val_accuracy: 0.8846\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5429 - accuracy: 0.7700 - val_loss: 0.3255 - val_accuracy: 0.8846\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5510 - accuracy: 0.7700 - val_loss: 0.5251 - val_accuracy: 0.8846\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 0.5466 - accuracy: 0.7700 - val_loss: 0.3479 - val_accuracy: 0.8846\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 3s 721ms/step - loss: 0.5394 - accuracy: 0.7700 - val_loss: 0.4032 - val_accuracy: 0.9231\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.5963 - accuracy: 0.7700 - val_loss: 0.2649 - val_accuracy: 0.8846\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 4s 791ms/step - loss: 0.6095 - accuracy: 0.7700 - val_loss: 0.4380 - val_accuracy: 0.9615\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 3s 715ms/step - loss: 0.5302 - accuracy: 0.7800 - val_loss: 0.4390 - val_accuracy: 0.9231\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5280 - accuracy: 0.7800 - val_loss: 0.4897 - val_accuracy: 0.9231\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5224 - accuracy: 0.7700 - val_loss: 0.4697 - val_accuracy: 0.8846\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 3s 959ms/step - loss: 0.5310 - accuracy: 0.7700 - val_loss: 0.4683 - val_accuracy: 0.8077\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 3s 962ms/step - loss: 0.5663 - accuracy: 0.7700 - val_loss: 0.5170 - val_accuracy: 0.8077\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.5240 - accuracy: 0.7500 - val_loss: 0.3892 - val_accuracy: 0.9615\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5290 - accuracy: 0.7900 - val_loss: 0.5937 - val_accuracy: 0.8077\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5167 - accuracy: 0.7800 - val_loss: 0.4340 - val_accuracy: 0.8846\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 3s 985ms/step - loss: 0.5346 - accuracy: 0.7700 - val_loss: 0.3152 - val_accuracy: 0.9231\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 3s 974ms/step - loss: 0.5511 - accuracy: 0.7600 - val_loss: 0.6529 - val_accuracy: 0.6154\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5250 - accuracy: 0.8000 - val_loss: 0.4000 - val_accuracy: 0.9615\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 4s 832ms/step - loss: 0.5109 - accuracy: 0.7800 - val_loss: 0.3688 - val_accuracy: 0.9231\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.5248 - accuracy: 0.7800 - val_loss: 0.3966 - val_accuracy: 0.9615\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 3s 709ms/step - loss: 0.5238 - accuracy: 0.7600 - val_loss: 0.4926 - val_accuracy: 0.8077\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.4984 - accuracy: 0.7900 - val_loss: 0.4620 - val_accuracy: 0.8077\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 3s 725ms/step - loss: 0.5307 - accuracy: 0.7700 - val_loss: 0.3913 - val_accuracy: 0.8846\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 3s 715ms/step - loss: 0.5346 - accuracy: 0.7700 - val_loss: 0.8100 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.5462 - accuracy: 0.7900 - val_loss: 0.4101 - val_accuracy: 0.8462\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5063 - accuracy: 0.8000 - val_loss: 0.3200 - val_accuracy: 0.9231\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.5161 - accuracy: 0.8000 - val_loss: 0.7032 - val_accuracy: 0.6154\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.5782 - accuracy: 0.7400 - val_loss: 0.7596 - val_accuracy: 0.5769\n"
          ]
        }
      ],
      "source": [
        "# Convert labels to integers\n",
        "label_dict = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
        "y_train = np.array([label_dict[label] for label in y_train])\n",
        "y_test = np.array([label_dict[label] for label in y_test])\n",
        "\n",
        "# Model architecture\n",
        "image_height, image_width = X_train.shape[1], X_train.shape[2]\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_dict), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0b6pt8tZ9Au"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLAMz8ujZ9Ds"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5V0hzkUZ9Gy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9kd8w_PZ9Jj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Oize8DPONl",
        "outputId": "2c80900f-0878-4bdf-dfbd-8ab7e9bed21e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save(\"benign_malignant_classifier.h5\")\n",
        "\n",
        "# Load and use the saved model\n",
        "model = load_model(\"benign_malignant_classifier.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGTuYxt3PxG-",
        "outputId": "463923b1-a731-44b0-a0fe-a9ba03bcade0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 138ms/step\n",
            "Predicted label: [0]\n"
          ]
        }
      ],
      "source": [
        "# Example prediction\n",
        "example_image = X_test[0]\n",
        "prediction = model.predict(np.expand_dims(example_image, axis=0))\n",
        "predicted_label = np.argmax(prediction, axis=1)\n",
        "print(f\"Predicted label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8BK-C7hSgj7"
      },
      "source": [
        "# **Dependencies:**\n",
        "\n",
        "Ensure all required libraries are installed. Use the pip install commands provided.\n",
        "Data Paths: Update dataset_path and other file paths as necessary to match your local environment.\n",
        "Model Adjustments: Depending on your dataset and requirements, you may need to tweak the model architecture or parameters.\n",
        "Feel free to adjust the documentation according to any specific requirements or additional details of your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k4iAKmKaAjL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VQfYk9raAml",
        "outputId": "e65e9550-f012-468b-f584-7aeaa59c3586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (0.6.23)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.23.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.7.24)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-pptx Pillow scikit-image opencv-python xlsxwriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PTrHcyvaApL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1pF6qbgaAsD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-see-R3aAxV",
        "outputId": "0141195a-a8e3-4d3a-a607-05c1d1dff9bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from pptx import Presentation\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset path and output directories\n",
        "dataset_path = '/content/drive/MyDrive/your_dataset_folder'\n",
        "output_image_dir = '/content/images'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(output_image_dir):\n",
        "    os.makedirs(output_image_dir)\n",
        "\n",
        "def extract_images_from_pptx(pptx_path, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    presentation = Presentation(pptx_path)\n",
        "    for idx, slide in enumerate(presentation.slides):\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"image\"):\n",
        "                image = shape.image\n",
        "                image_bytes = image.blob\n",
        "                image_stream = BytesIO(image_bytes)\n",
        "                img = Image.open(image_stream)\n",
        "                img.save(os.path.join(output_dir, f\"slide{idx}.png\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EUS2c00aA02"
      },
      "outputs": [],
      "source": [
        "# Extract images from each PowerPoint file\n",
        "pptx_files = [\"EPC Colony Quiz 2 - unlabeled70.pptx\", \"EPC Colony Quiz_unlabeled.pptx\", \"EPC-CFU Labeled-images.pptx\"]\n",
        "for pptx_file in pptx_files:\n",
        "    extract_images_from_pptx(os.path.join(dataset_path, pptx_file), os.path.join(output_image_dir, pptx_file.split('.')[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvoGT3SscN_V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4ss39dcc_6V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeCJe_et973I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RJzWLAzbF4FV7dA_0CBGgmS6FOsyVPIp",
      "authorship_tag": "ABX9TyMV0loTyRB9mffDlLeWXoC3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}